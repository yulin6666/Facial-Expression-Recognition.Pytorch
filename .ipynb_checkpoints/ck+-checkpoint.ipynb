{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981, 48, 48)\n",
      "(981,)\n",
      "Save data finish!!!\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_CK+.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "882 99\n",
      "882 99\n",
      "==> Building model..\n",
      "\n",
      "Epoch: 0\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.925 | Acc: 29.000% (260/882)        7/7 \n",
      "mainpro_CK+.py:141: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
      " [============================>.] | Loss: 1.950 | Acc: 12.000% (12/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 12.000\n",
      "\n",
      "Epoch: 1\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 1.363 | Acc: 48.000% (426/882)        7/7 \n",
      " [============================>.] | Loss: 2.103 | Acc: 6.000% (6/99)            20/20 \n",
      "\n",
      "Epoch: 2\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.968 | Acc: 61.000% (546/882)        7/7 \n",
      " [============================>.] | Loss: 2.571 | Acc: 6.000% (6/99)            20/20 \n",
      "\n",
      "Epoch: 3\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.692 | Acc: 71.000% (632/882)        7/7 \n",
      " [============================>.] | Loss: 2.509 | Acc: 18.000% (18/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 18.000\n",
      "\n",
      "Epoch: 4\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.535 | Acc: 80.000% (709/882)        7/7 \n",
      " [============================>.] | Loss: 1.492 | Acc: 51.000% (51/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 51.000\n",
      "\n",
      "Epoch: 5\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.441 | Acc: 83.000% (739/882)        7/7 \n",
      " [============================>.] | Loss: 1.412 | Acc: 34.000% (34/99)          20/20 \n",
      "\n",
      "Epoch: 6\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.405 | Acc: 85.000% (753/882)        7/7 \n",
      " [============================>.] | Loss: 1.127 | Acc: 68.000% (68/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 68.000\n",
      "\n",
      "Epoch: 7\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.366 | Acc: 86.000% (766/882)        7/7 \n",
      " [============================>.] | Loss: 0.789 | Acc: 70.000% (70/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 70.000\n",
      "\n",
      "Epoch: 8\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.356 | Acc: 86.000% (767/882)        7/7 \n",
      " [============================>.] | Loss: 0.554 | Acc: 83.000% (83/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 83.000\n",
      "\n",
      "Epoch: 9\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.252 | Acc: 91.000% (806/882)        7/7 \n",
      " [============================>.] | Loss: 0.734 | Acc: 79.000% (79/99)          20/20 \n",
      "\n",
      "Epoch: 10\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.247 | Acc: 91.000% (809/882)        7/7 \n",
      " [============================>.] | Loss: 0.375 | Acc: 80.000% (80/99)          20/20 \n",
      "\n",
      "Epoch: 11\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.183 | Acc: 93.000% (829/882)        7/7 \n",
      " [============================>.] | Loss: 0.599 | Acc: 78.000% (78/99)          20/20 \n",
      "\n",
      "Epoch: 12\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.138 | Acc: 96.000% (848/882)        7/7 \n",
      " [============================>.] | Loss: 0.459 | Acc: 78.000% (78/99)          20/20 \n",
      "\n",
      "Epoch: 13\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.137 | Acc: 95.000% (845/882)        7/7 \n",
      " [============================>.] | Loss: 0.562 | Acc: 85.000% (85/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 85.000\n",
      "\n",
      "Epoch: 14\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.114 | Acc: 96.000% (847/882)        7/7 \n",
      " [============================>.] | Loss: 0.547 | Acc: 78.000% (78/99)          20/20 \n",
      "\n",
      "Epoch: 15\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.101 | Acc: 96.000% (851/882)        7/7 \n",
      " [============================>.] | Loss: 0.718 | Acc: 75.000% (75/99)          20/20 \n",
      "\n",
      "Epoch: 16\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.066 | Acc: 98.000% (867/882)        7/7 \n",
      " [============================>.] | Loss: 0.479 | Acc: 74.000% (74/99)          20/20 \n",
      "\n",
      "Epoch: 17\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.076 | Acc: 97.000% (858/882)        7/7 \n",
      " [============================>.] | Loss: 0.310 | Acc: 87.000% (87/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 87.000\n",
      "\n",
      "Epoch: 18\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.058 | Acc: 98.000% (866/882)        7/7 \n",
      " [============================>.] | Loss: 0.785 | Acc: 76.000% (76/99)          20/20 \n",
      "\n",
      "Epoch: 19\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.082 | Acc: 97.000% (857/882)        7/7 \n",
      " [============================>.] | Loss: 0.257 | Acc: 91.000% (91/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 91.000\n",
      "\n",
      "Epoch: 20\n",
      "learning_rate: 0.01\n",
      " [=========================>....] | Loss: 0.079 | Acc: 97.000% (864/882)        7/7 \n",
      " [============================>.] | Loss: 1.023 | Acc: 65.000% (65/99)          20/20 \n",
      "\n",
      "Epoch: 21\n",
      "learning_rate: 0.008\n",
      " [=========================>....] | Loss: 0.035 | Acc: 98.000% (872/882)        7/7 \n",
      " [============================>.] | Loss: 0.257 | Acc: 94.000% (94/99)          20/20 \n",
      "Saving..\n",
      "best_Test_acc: 94.000\n",
      "\n",
      "Epoch: 22\n",
      "learning_rate: 0.006400000000000001\n",
      " [=========================>....] | Loss: 0.055 | Acc: 98.000% (868/882)        7/7 \n",
      " [============================>.] | Loss: 0.161 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 23\n",
      "learning_rate: 0.005120000000000001\n",
      " [=========================>....] | Loss: 0.042 | Acc: 98.000% (872/882)        7/7 \n",
      " [============================>.] | Loss: 0.207 | Acc: 94.000% (94/99)          20/20 \n",
      "\n",
      "Epoch: 24\n",
      "learning_rate: 0.004096000000000001\n",
      " [=========================>....] | Loss: 0.024 | Acc: 99.000% (877/882)        7/7 \n",
      " [============================>.] | Loss: 0.166 | Acc: 90.000% (90/99)          20/20 \n",
      "\n",
      "Epoch: 25\n",
      "learning_rate: 0.0032768000000000007\n",
      " [=========================>....] | Loss: 0.021 | Acc: 99.000% (876/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 91.000% (91/99)          20/20 \n",
      "\n",
      "Epoch: 26\n",
      "learning_rate: 0.002621440000000001\n",
      " [=========================>....] | Loss: 0.014 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.160 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 27\n",
      "learning_rate: 0.002097152000000001\n",
      " [=========================>....] | Loss: 0.021 | Acc: 99.000% (876/882)        7/7 \n",
      " [============================>.] | Loss: 0.173 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 28\n",
      "learning_rate: 0.001677721600000001\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.180 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 29\n",
      "learning_rate: 0.0013421772800000006\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.180 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 30\n",
      "learning_rate: 0.0010737418240000006\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.176 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 31\n",
      "learning_rate: 0.0008589934592000006\n",
      " [=========================>....] | Loss: 0.013 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.170 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 32\n",
      "learning_rate: 0.0006871947673600004\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.166 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 33\n",
      "learning_rate: 0.0005497558138880004\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.168 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 34\n",
      "learning_rate: 0.00043980465111040037\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.160 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 35\n",
      "learning_rate: 0.0003518437208883203\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.159 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 36\n",
      "learning_rate: 0.00028147497671065624\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.159 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 37\n",
      "learning_rate: 0.00022517998136852504\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 38\n",
      "learning_rate: 0.00018014398509482002\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 39\n",
      "learning_rate: 0.00014411518807585602\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 40\n",
      "learning_rate: 0.00011529215046068484\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 41\n",
      "learning_rate: 9.223372036854788e-05\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 42\n",
      "learning_rate: 7.37869762948383e-05\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 43\n",
      "learning_rate: 5.902958103587064e-05\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 44\n",
      "learning_rate: 4.722366482869652e-05\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 45\n",
      "learning_rate: 3.777893186295722e-05\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 46\n",
      "learning_rate: 3.0223145490365776e-05\n",
      " [=========================>....] | Loss: 0.008 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 47\n",
      "learning_rate: 2.417851639229262e-05\n",
      " [=========================>....] | Loss: 0.006 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 48\n",
      "learning_rate: 1.9342813113834096e-05\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 49\n",
      "learning_rate: 1.547425049106728e-05\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 50\n",
      "learning_rate: 1.2379400392853824e-05\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 51\n",
      "learning_rate: 9.903520314283058e-06\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 52\n",
      "learning_rate: 7.922816251426448e-06\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.158 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 53\n",
      "learning_rate: 6.338253001141158e-06\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 54\n",
      "learning_rate: 5.0706024009129275e-06\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 55\n",
      "learning_rate: 4.056481920730342e-06\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 56\n",
      "learning_rate: 3.2451855365842735e-06\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 57\n",
      "learning_rate: 2.5961484292674196e-06\n",
      " [=========================>....] | Loss: 0.013 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 58\n",
      "learning_rate: 2.0769187434139356e-06\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 59\n",
      "learning_rate: 1.6615349947311485e-06\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 60\n",
      "learning_rate: 1.3292279957849189e-06\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 61\n",
      "learning_rate: 1.0633823966279351e-06\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.150 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 62\n",
      "learning_rate: 8.507059173023481e-07\n",
      " [=========================>....] | Loss: 0.006 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 63\n",
      "learning_rate: 6.805647338418786e-07\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 64\n",
      "learning_rate: 5.444517870735029e-07\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 65\n",
      "learning_rate: 4.3556142965880233e-07\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 66\n",
      "learning_rate: 3.484491437270419e-07\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 67\n",
      "learning_rate: 2.787593149816335e-07\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 68\n",
      "learning_rate: 2.2300745198530684e-07\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 69\n",
      "learning_rate: 1.784059615882455e-07\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (877/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 70\n",
      "learning_rate: 1.4272476927059639e-07\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 71\n",
      "learning_rate: 1.1417981541647711e-07\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 72\n",
      "learning_rate: 9.13438523331817e-08\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 73\n",
      "learning_rate: 7.307508186654536e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 74\n",
      "learning_rate: 5.846006549323629e-08\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.151 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 75\n",
      "learning_rate: 4.676805239458904e-08\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.151 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 76\n",
      "learning_rate: 3.741444191567123e-08\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 77\n",
      "learning_rate: 2.9931553532536985e-08\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 78\n",
      "learning_rate: 2.3945242826029592e-08\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 79\n",
      "learning_rate: 1.9156194260823674e-08\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 80\n",
      "learning_rate: 1.532495540865894e-08\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 81\n",
      "learning_rate: 1.2259964326927151e-08\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 82\n",
      "learning_rate: 9.807971461541723e-09\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 83\n",
      "learning_rate: 7.846377169233378e-09\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 84\n",
      "learning_rate: 6.277101735386703e-09\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 85\n",
      "learning_rate: 5.0216813883093625e-09\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 86\n",
      "learning_rate: 4.017345110647491e-09\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 87\n",
      "learning_rate: 3.2138760885179924e-09\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 88\n",
      "learning_rate: 2.5711008708143944e-09\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 89\n",
      "learning_rate: 2.0568806966515157e-09\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 90\n",
      "learning_rate: 1.6455045573212124e-09\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 91\n",
      "learning_rate: 1.31640364585697e-09\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 92\n",
      "learning_rate: 1.0531229166855762e-09\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 93\n",
      "learning_rate: 8.42498333348461e-10\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.159 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 94\n",
      "learning_rate: 6.739986666787687e-10\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.160 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 95\n",
      "learning_rate: 5.39198933343015e-10\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 96\n",
      "learning_rate: 4.3135914667441205e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 97\n",
      "learning_rate: 3.450873173395297e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 98\n",
      "learning_rate: 2.7606985387162373e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 99\n",
      "learning_rate: 2.2085588309729901e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 100\n",
      "learning_rate: 1.7668470647783923e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 101\n",
      "learning_rate: 1.413477651822714e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 102\n",
      "learning_rate: 1.130782121458171e-10\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 103\n",
      "learning_rate: 9.04625697166537e-11\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 104\n",
      "learning_rate: 7.237005577332295e-11\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 105\n",
      "learning_rate: 5.789604461865837e-11\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.151 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 106\n",
      "learning_rate: 4.63168356949267e-11\n",
      " [=========================>....] | Loss: 0.008 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 107\n",
      "learning_rate: 3.7053468555941365e-11\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 108\n",
      "learning_rate: 2.964277484475309e-11\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 109\n",
      "learning_rate: 2.3714219875802474e-11\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 110\n",
      "learning_rate: 1.8971375900641982e-11\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 111\n",
      "learning_rate: 1.5177100720513584e-11\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 112\n",
      "learning_rate: 1.2141680576410869e-11\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 113\n",
      "learning_rate: 9.713344461128697e-12\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 114\n",
      "learning_rate: 7.770675568902958e-12\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 115\n",
      "learning_rate: 6.216540455122366e-12\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 116\n",
      "learning_rate: 4.973232364097893e-12\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 117\n",
      "learning_rate: 3.978585891278314e-12\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 118\n",
      "learning_rate: 3.182868713022652e-12\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 119\n",
      "learning_rate: 2.5462949704181215e-12\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 120\n",
      "learning_rate: 2.0370359763344977e-12\n",
      " [=========================>....] | Loss: 0.013 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 121\n",
      "learning_rate: 1.629628781067598e-12\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 122\n",
      "learning_rate: 1.3037030248540785e-12\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 123\n",
      "learning_rate: 1.0429624198832629e-12\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 124\n",
      "learning_rate: 8.343699359066104e-13\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 125\n",
      "learning_rate: 6.674959487252882e-13\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 126\n",
      "learning_rate: 5.339967589802307e-13\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 127\n",
      "learning_rate: 4.2719740718418454e-13\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 128\n",
      "learning_rate: 3.4175792574734765e-13\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 129\n",
      "learning_rate: 2.7340634059787813e-13\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 130\n",
      "learning_rate: 2.1872507247830254e-13\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 131\n",
      "learning_rate: 1.7498005798264204e-13\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 132\n",
      "learning_rate: 1.3998404638611363e-13\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 133\n",
      "learning_rate: 1.1198723710889092e-13\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 134\n",
      "learning_rate: 8.958978968711274e-14\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 135\n",
      "learning_rate: 7.167183174969019e-14\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 136\n",
      "learning_rate: 5.733746539975217e-14\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 137\n",
      "learning_rate: 4.5869972319801734e-14\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 138\n",
      "learning_rate: 3.669597785584139e-14\n",
      " [=========================>....] | Loss: 0.007 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 139\n",
      "learning_rate: 2.935678228467311e-14\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 140\n",
      "learning_rate: 2.3485425827738488e-14\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.158 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 141\n",
      "learning_rate: 1.878834066219079e-14\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.158 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 142\n",
      "learning_rate: 1.5030672529752636e-14\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 143\n",
      "learning_rate: 1.2024538023802108e-14\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 144\n",
      "learning_rate: 9.619630419041687e-15\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 145\n",
      "learning_rate: 7.69570433523335e-15\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 146\n",
      "learning_rate: 6.15656346818668e-15\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.150 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 147\n",
      "learning_rate: 4.925250774549344e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.151 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 148\n",
      "learning_rate: 3.940200619639476e-15\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 149\n",
      "learning_rate: 3.1521604957115808e-15\n",
      " [=========================>....] | Loss: 0.008 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 150\n",
      "learning_rate: 2.521728396569265e-15\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 151\n",
      "learning_rate: 2.017382717255412e-15\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 152\n",
      "learning_rate: 1.6139061738043298e-15\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 153\n",
      "learning_rate: 1.2911249390434638e-15\n",
      " [=========================>....] | Loss: 0.007 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 154\n",
      "learning_rate: 1.0328999512347711e-15\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 155\n",
      "learning_rate: 8.263199609878169e-16\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 156\n",
      "learning_rate: 6.610559687902537e-16\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 157\n",
      "learning_rate: 5.288447750322029e-16\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 158\n",
      "learning_rate: 4.2307582002576235e-16\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 159\n",
      "learning_rate: 3.384606560206099e-16\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 160\n",
      "learning_rate: 2.7076852481648796e-16\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 161\n",
      "learning_rate: 2.1661481985319035e-16\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 162\n",
      "learning_rate: 1.732918558825523e-16\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 163\n",
      "learning_rate: 1.3863348470604184e-16\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.151 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 164\n",
      "learning_rate: 1.1090678776483348e-16\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 165\n",
      "learning_rate: 8.87254302118668e-17\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 166\n",
      "learning_rate: 7.098034416949344e-17\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 167\n",
      "learning_rate: 5.678427533559476e-17\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 168\n",
      "learning_rate: 4.5427420268475807e-17\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 169\n",
      "learning_rate: 3.6341936214780644e-17\n",
      " [=========================>....] | Loss: 0.008 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 170\n",
      "learning_rate: 2.907354897182452e-17\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 171\n",
      "learning_rate: 2.3258839177459616e-17\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 172\n",
      "learning_rate: 1.8607071341967693e-17\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 173\n",
      "learning_rate: 1.4885657073574156e-17\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 174\n",
      "learning_rate: 1.1908525658859325e-17\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 175\n",
      "learning_rate: 9.52682052708746e-18\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 176\n",
      "learning_rate: 7.62145642166997e-18\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 177\n",
      "learning_rate: 6.0971651373359754e-18\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 178\n",
      "learning_rate: 4.877732109868781e-18\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 179\n",
      "learning_rate: 3.902185687895025e-18\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 180\n",
      "learning_rate: 3.12174855031602e-18\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 181\n",
      "learning_rate: 2.497398840252816e-18\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 182\n",
      "learning_rate: 1.997919072202253e-18\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 183\n",
      "learning_rate: 1.5983352577618025e-18\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 184\n",
      "learning_rate: 1.278668206209442e-18\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 185\n",
      "learning_rate: 1.0229345649675538e-18\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 186\n",
      "learning_rate: 8.18347651974043e-19\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 187\n",
      "learning_rate: 6.546781215792345e-19\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.161 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 188\n",
      "learning_rate: 5.237424972633876e-19\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 189\n",
      "learning_rate: 4.189939978107101e-19\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 190\n",
      "learning_rate: 3.3519519824856807e-19\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 191\n",
      "learning_rate: 2.681561585988545e-19\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 192\n",
      "learning_rate: 2.145249268790836e-19\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 193\n",
      "learning_rate: 1.7161994150326688e-19\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.151 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 194\n",
      "learning_rate: 1.3729595320261352e-19\n",
      " [=========================>....] | Loss: 0.015 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 195\n",
      "learning_rate: 1.098367625620908e-19\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.150 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 196\n",
      "learning_rate: 8.786941004967267e-20\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 197\n",
      "learning_rate: 7.029552803973813e-20\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 198\n",
      "learning_rate: 5.623642243179051e-20\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 199\n",
      "learning_rate: 4.498913794543241e-20\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 200\n",
      "learning_rate: 3.5991310356345934e-20\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 201\n",
      "learning_rate: 2.8793048285076746e-20\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 202\n",
      "learning_rate: 2.30344386280614e-20\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 203\n",
      "learning_rate: 1.8427550902449122e-20\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 204\n",
      "learning_rate: 1.4742040721959298e-20\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 205\n",
      "learning_rate: 1.1793632577567439e-20\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 206\n",
      "learning_rate: 9.43490606205395e-21\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 207\n",
      "learning_rate: 7.547924849643161e-21\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 208\n",
      "learning_rate: 6.0383398797145295e-21\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 209\n",
      "learning_rate: 4.8306719037716234e-21\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 210\n",
      "learning_rate: 3.864537523017299e-21\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 211\n",
      "learning_rate: 3.0916300184138396e-21\n",
      " [=========================>....] | Loss: 0.013 | Acc: 99.000% (877/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 212\n",
      "learning_rate: 2.4733040147310717e-21\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 213\n",
      "learning_rate: 1.9786432117848575e-21\n",
      " [=========================>....] | Loss: 0.008 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 214\n",
      "learning_rate: 1.5829145694278862e-21\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.158 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 215\n",
      "learning_rate: 1.266331655542309e-21\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 216\n",
      "learning_rate: 1.0130653244338472e-21\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 217\n",
      "learning_rate: 8.104522595470779e-22\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 218\n",
      "learning_rate: 6.483618076376623e-22\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 219\n",
      "learning_rate: 5.186894461101298e-22\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 220\n",
      "learning_rate: 4.149515568881039e-22\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 221\n",
      "learning_rate: 3.3196124551048316e-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=========================>....] | Loss: 0.008 | Acc: 100.000% (882/882)       7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 222\n",
      "learning_rate: 2.6556899640838656e-22\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 223\n",
      "learning_rate: 2.1245519712670924e-22\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 224\n",
      "learning_rate: 1.699641577013674e-22\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 225\n",
      "learning_rate: 1.3597132616109392e-22\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 226\n",
      "learning_rate: 1.0877706092887513e-22\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 227\n",
      "learning_rate: 8.702164874310012e-23\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 228\n",
      "learning_rate: 6.96173189944801e-23\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.155 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 229\n",
      "learning_rate: 5.569385519558409e-23\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 230\n",
      "learning_rate: 4.455508415646727e-23\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 231\n",
      "learning_rate: 3.5644067325173816e-23\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 232\n",
      "learning_rate: 2.851525386013906e-23\n",
      " [=========================>....] | Loss: 0.013 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 233\n",
      "learning_rate: 2.2812203088111247e-23\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 234\n",
      "learning_rate: 1.8249762470489e-23\n",
      " [=========================>....] | Loss: 0.012 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 235\n",
      "learning_rate: 1.45998099763912e-23\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 236\n",
      "learning_rate: 1.167984798111296e-23\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 237\n",
      "learning_rate: 9.343878384890368e-24\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 238\n",
      "learning_rate: 7.475102707912296e-24\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 239\n",
      "learning_rate: 5.9800821663298366e-24\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 240\n",
      "learning_rate: 4.784065733063869e-24\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.154 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 241\n",
      "learning_rate: 3.827252586451096e-24\n",
      " [=========================>....] | Loss: 0.008 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.157 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 242\n",
      "learning_rate: 3.061802069160877e-24\n",
      " [=========================>....] | Loss: 0.007 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.156 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 243\n",
      "learning_rate: 2.4494416553287016e-24\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 244\n",
      "learning_rate: 1.9595533242629614e-24\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (881/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 245\n",
      "learning_rate: 1.5676426594103693e-24\n",
      " [=========================>....] | Loss: 0.013 | Acc: 99.000% (880/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 246\n",
      "learning_rate: 1.2541141275282953e-24\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (878/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 247\n",
      "learning_rate: 1.0032913020226365e-24\n",
      " [=========================>....] | Loss: 0.009 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 248\n",
      "learning_rate: 8.026330416181091e-25\n",
      " [=========================>....] | Loss: 0.010 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.153 | Acc: 93.000% (93/99)          20/20 \n",
      "\n",
      "Epoch: 249\n",
      "learning_rate: 6.421064332944874e-25\n",
      " [=========================>....] | Loss: 0.011 | Acc: 99.000% (879/882)        7/7 \n",
      " [============================>.] | Loss: 0.152 | Acc: 93.000% (93/99)          20/20 \n",
      "best_Test_acc: 94.000\n",
      "best_Test_acc_epoch: 21\n"
     ]
    }
   ],
   "source": [
    "!python mainpro_CK+.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin      5.899\n",
      "origin      0.868\n",
      "origin     -3.237\n",
      "origin     -2.626\n",
      "origin      2.764\n",
      "origin     -0.591\n",
      "origin      1.633\n",
      "     0.938\n",
      "     0.006\n",
      "     0.000\n",
      "     0.000\n",
      "     0.041\n",
      "     0.001\n",
      "     0.013\n",
      "The Expression is Angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    }
   ],
   "source": [
    "#验证模型正确性\n",
    "\"\"\"\n",
    "visualize results for test image\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transforms as transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from models import *\n",
    "\n",
    "cut_size = 44\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "raw_img = io.imread('images/anger.png')\n",
    "img = raw_img[:, :, np.newaxis]\n",
    "img = np.concatenate((img, img, img), axis=2)\n",
    "img = Image.fromarray(img)\n",
    "inputs = transform_test(img)\n",
    "\n",
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "net = VGG('VGG19')\n",
    "checkpoint = torch.load(os.path.join('CK+_VGG19/1/', 'Test_model.t7'))\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "net.cuda()\n",
    "net.eval()\n",
    "\n",
    "c, h, w = np.shape(inputs)\n",
    "inputs = inputs.view(-1, c, h, w)\n",
    "inputs = inputs.cuda()\n",
    "inputs = Variable(inputs, volatile=True)\n",
    "outputs = net(inputs)\n",
    "for i in range(7):\n",
    "  print('origin %10.3f' % outputs[0][i])\n",
    "\n",
    "score = F.softmax(outputs,1)\n",
    "max = score[0][0]\n",
    "maxindex = 0\n",
    "for i in range(7):\n",
    "  print('%10.3f' % score[0][i])\n",
    "  if(score[0][i] > max):\n",
    "        max = score[0][i]\n",
    "        maxindex = i\n",
    "\n",
    "\n",
    "        print(\"The Expression is %s\" %str(class_names[maxindex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (1.5.0)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx) (1.12.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from onnx) (1.17.0)\r\n",
      "Requirement already satisfied: typing>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.7.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.7.4.1)\r\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx) (3.9.1)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx) (41.0.1)\r\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0ce60018ae0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mraw_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/anger.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gray' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install onnx\n",
    "#转成onnx模型\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transforms as transforms\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from models import *\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "img = io.imread('images/anger.png')\n",
    "img = img[:, :, np.newaxis]\n",
    "img = np.concatenate((img, img, img), axis=2)\n",
    "img = Image.fromarray(img)\n",
    "inputs = transform_test(img)\n",
    "\n",
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "#导入模型，用训练模式\n",
    "net = VGG('VGG19')\n",
    "checkpoint = torch.load(os.path.join('CK+_VGG19/1/', 'Test_model.t7'))\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "net.cuda()\n",
    "net.train(False)\n",
    "\n",
    "#模拟input\n",
    "c, h, w = np.shape(inputs)\n",
    "inputs = inputs.view(-1,c, h, w)\n",
    "inputs = inputs.cuda()\n",
    "inputs = Variable(inputs, volatile=True)\n",
    "#导出模型\n",
    "torch_out = torch.onnx._export(net,  # model being run\n",
    "                               inputs,  # model input (or a tuple for multiple inputs)\n",
    "                               \"CK+_VGG19_privateTest.onnx\",  # where to save the model\n",
    "                               verbose=True,\n",
    "                               input_names=['data'], \n",
    "                               output_names=['outTensor'], \n",
    "                               export_params=True, \n",
    "                               training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
